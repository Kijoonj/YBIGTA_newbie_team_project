import os
from langchain_upstage import ChatUpstage, UpstageEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import AIMessage

def rag_review_node(state):
    print("\n--- ğŸ”µ RAG Review Node ì§„ì… ---")
    
    user_query = state["messages"][-1].content
    
    # 1. ê²½ë¡œ ì„¤ì •
    current_file_path = os.path.abspath(__file__)
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_file_path)))
    index_path = os.path.join(project_root, "db", "faiss_index")
    
    try:
        # 2. FAISS ë¡œë“œ
        embeddings = UpstageEmbeddings(model="solar-embedding-1-large")
        vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)
        
        # 3. ê²€ìƒ‰ (k=3 -> k=5ë¡œ ëŠ˜ë ¤ì„œ ë” ë§ì€ ë¬¸ë§¥ í™•ë³´)
        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
        docs = retriever.invoke(user_query)
        
        # [ë””ë²„ê¹…] ê²€ìƒ‰ëœ ë‚´ìš© í„°ë¯¸ë„ì— ì¶œë ¥ (í•„ìˆ˜ í™•ì¸!)
        print(f"ğŸ” '{user_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼:")
        for i, doc in enumerate(docs):
            print(f"[{i+1}] {doc.page_content}")

        # 4. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ë¶€ì‹¤í•  ê²½ìš° ì²˜ë¦¬
        if not docs:
            return {"messages": [AIMessage(content="ê´€ë ¨ëœ ë¦¬ë·° ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")], "intent": "review"}

        context = "\n".join([f"- {doc.page_content}" for doc in docs])
        
        # 5. í”„ë¡¬í”„íŠ¸ (ì ‘ì†ì‚¬ ê¸ˆì§€ & ì‚¬ì‹¤ ê¸°ë°˜ ê°•ì œ)
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ëƒ‰ì² í•œ ë¦¬ë·° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
            ì œê³µëœ [ê²€ìƒ‰ëœ ë¦¬ë·°] ëª©ë¡ì„ ì½ê³  ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

            **ì ˆëŒ€ ì§€ì¼œì•¼ í•  ê·œì¹™:**
            1. **"ë˜í•œ", "í•˜ì§€ë§Œ", "ê·¸ë¦¬ê³ "** ê°™ì€ ì ‘ì†ì‚¬ë¡œ ë¬¸ì¥ì„ ì‹œì‘í•˜ì§€ ë§ˆì„¸ìš”. ë°”ë¡œ ê²°ë¡ ë¶€í„° ë§í•˜ì„¸ìš”.
            2. [ê²€ìƒ‰ëœ ë¦¬ë·°]ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
            3. ê¸ì •/ë¶€ì • ì˜ê²¬ì´ ìˆë‹¤ë©´ ê°€ê° ì—†ì´ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ì„¸ìš”. (ì˜ˆ: "ë°œì—´ì´ ìˆë‹¤ëŠ” ì˜ê²¬ì´ ìˆìŠµë‹ˆë‹¤.")
            4. ë§Œì•½ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¦¬ë·°ê°€ ëª©ë¡ì— í•˜ë‚˜ë„ ì—†ë‹¤ë©´, ì†”ì§í•˜ê²Œ "ê´€ë ¨ëœ ë¦¬ë·° ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.

            [ê²€ìƒ‰ëœ ë¦¬ë·°]
            {context}"""),
            ("human", "{query}")
        ])
        
        # 6. LLM ì‹¤í–‰
        llm = ChatUpstage(model="solar-pro", temperature=0)
        chain = prompt | llm
        response = chain.invoke({"context": context, "query": user_query})
        
        answer_text = response.content
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")
        answer_text = "ë¦¬ë·° ì‹œìŠ¤í…œì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    return {
        "messages": [AIMessage(content=answer_text)], 
        "intent": "review"
    }